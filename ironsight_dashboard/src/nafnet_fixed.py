"""
Fixed NAFNet Implementation

This module provides a corrected NAFNet implementation that properly handles:
1. GPU detection and fallback to CPU
2. Correct model architecture matching the checkpoint
3. Proper error handling and logging
4. Compatibility with different PyTorch versions
"""

import logging
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional, Tuple, Dict, Any
import numpy as np
import os

logger = logging.getLogger(__name__)


def detect_device() -> str:
    """
    Detect the best available device for computation.
    
    Returns:
        Device string: 'cuda' if available, otherwise 'cpu'
    """
    try:
        if torch.cuda.is_available():
            device_count = torch.cuda.device_count()
            device_name = torch.cuda.get_device_name(0) if device_count > 0 else "Unknown"
            logger.info(f"CUDA available: {device_count} device(s), using: {device_name}")
            return "cuda"
        else:
            logger.info("CUDA not available, using CPU")
            return "cpu"
    except Exception as e:
        logger.warning(f"Error detecting CUDA: {e}, falling back to CPU")
        return "cpu"


class LayerNorm(nn.Module):
    """Layer normalization for NAFNet."""
    
    def __init__(self, normalized_shape, eps=1e-6, data_format="channels_last"):
        super().__init__()
        self.weight = nn.Parameter(torch.ones(normalized_shape))
        self.bias = nn.Parameter(torch.zeros(normalized_shape))
        self.eps = eps
        self.data_format = data_format
        if self.data_format not in ["channels_last", "channels_first"]:
            raise NotImplementedError
        self.normalized_shape = (normalized_shape, )

    def forward(self, x):
        if self.data_format == "channels_last":
            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)
        elif self.data_format == "channels_first":
            u = x.mean(1, keepdim=True)
            s = (x - u).pow(2).mean(1, keepdim=True)
            x = (x - u) / torch.sqrt(s + self.eps)
            x = self.weight[:, None, None] * x + self.bias[:, None, None]
            return x


class SimpleGate(nn.Module):
    """Simple gating mechanism for NAFNet."""
    
    def forward(self, x):
        x1, x2 = x.chunk(2, dim=1)
        return x1 * x2


class NAFBlock(nn.Module):
    """NAF Block implementation."""
    
    def __init__(self, c, DW_Expand=2, FFN_Expand=2, drop_out_rate=0.):
        super().__init__()
        dw_channel = c * DW_Expand
        self.conv1 = nn.Conv2d(in_channels=c, out_channels=dw_channel, kernel_size=1, padding=0, stride=1, groups=1, bias=True)
        self.conv2 = nn.Conv2d(in_channels=dw_channel, out_channels=dw_channel, kernel_size=3, padding=1, stride=1, groups=dw_channel,
                               bias=True)
        self.conv3 = nn.Conv2d(in_channels=dw_channel // 2, out_channels=c, kernel_size=1, padding=0, stride=1, groups=1, bias=True)
        
        # Simplified Channel Attention
        self.sca = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(in_channels=dw_channel // 2, out_channels=dw_channel // 2, kernel_size=1, padding=0, stride=1,
                      groups=1, bias=True),
        )

        # SimpleGate
        self.sg = SimpleGate()

        ffn_channel = FFN_Expand * c
        self.conv4 = nn.Conv2d(in_channels=c, out_channels=ffn_channel, kernel_size=1, padding=0, stride=1, groups=1, bias=True)
        self.conv5 = nn.Conv2d(in_channels=ffn_channel // 2, out_channels=c, kernel_size=1, padding=0, stride=1, groups=1, bias=True)

        self.norm1 = LayerNorm(c, data_format='channels_first')
        self.norm2 = LayerNorm(c, data_format='channels_first')

        self.dropout1 = nn.Dropout(drop_out_rate) if drop_out_rate > 0. else nn.Identity()
        self.dropout2 = nn.Dropout(drop_out_rate) if drop_out_rate > 0. else nn.Identity()

        self.beta = nn.Parameter(torch.zeros((1, c, 1, 1)), requires_grad=True)
        self.gamma = nn.Parameter(torch.zeros((1, c, 1, 1)), requires_grad=True)

    def forward(self, inp):
        x = inp

        x = self.norm1(x)

        x = self.conv1(x)
        x = self.conv2(x)
        x = self.sg(x)
        x = x * self.sca(x)
        x = self.conv3(x)

        x = self.dropout1(x)

        y = inp + x * self.beta

        x = self.conv4(self.norm2(y))
        x = self.sg(x)
        x = self.conv5(x)

        x = self.dropout2(x)

        return y + x * self.gamma


class FixedNAFNet(nn.Module):
    """
    Fixed NAFNet implementation that matches the actual checkpoint architecture.
    
    This implementation correctly handles the NAFNet-REDS-width64 model structure
    by analyzing the checkpoint and matching the layer configuration.
    """
    
    def __init__(self, img_channel=3, width=64, middle_blk_num=12, 
                 enc_blk_nums=None, dec_blk_nums=None):
        super().__init__()
        
        # Default configurations that match the checkpoint
        if enc_blk_nums is None:
            enc_blk_nums = [2, 2, 4, 28]  # Updated to match checkpoint
        if dec_blk_nums is None:
            dec_blk_nums = [2, 2, 2, 2]

        self.intro = nn.Conv2d(in_channels=img_channel, out_channels=width, kernel_size=3, padding=1, stride=1, groups=1,
                              bias=True)
        self.ending = nn.Conv2d(in_channels=width, out_channels=img_channel, kernel_size=3, padding=1, stride=1, groups=1,
                              bias=True)

        self.encoders = nn.ModuleList()
        self.decoders = nn.ModuleList()
        self.middle_blks = nn.ModuleList()
        self.ups = nn.ModuleList()
        self.downs = nn.ModuleList()

        chan = width
        for num in enc_blk_nums:
            self.encoders.append(
                nn.Sequential(
                    *[NAFBlock(chan) for _ in range(num)]
                )
            )
            self.downs.append(
                nn.Conv2d(chan, 2*chan, 2, 2)
            )
            chan = chan * 2

        self.middle_blks = \
            nn.Sequential(
                *[NAFBlock(chan) for _ in range(middle_blk_num)]
            )

        for num in dec_blk_nums:
            self.ups.append(
                nn.Sequential(
                    nn.Conv2d(chan, chan * 2, 1, bias=False),
                    nn.PixelShuffle(2)
                )
            )
            chan = chan // 2
            self.decoders.append(
                nn.Sequential(
                    *[NAFBlock(chan) for _ in range(num)]
                )
            )

        self.padder_size = 2 ** len(self.encoders)

    def forward(self, inp):
        B, C, H, W = inp.shape
        inp = self.check_image_size(inp)

        x = self.intro(inp)

        encs = []

        for encoder, down in zip(self.encoders, self.downs):
            x = encoder(x)
            encs.append(x)
            x = down(x)

        x = self.middle_blks(x)

        for decoder, up, enc_skip in zip(self.decoders, self.ups, encs[::-1]):
            x = up(x)
            x = x + enc_skip
            x = decoder(x)

        x = self.ending(x)
        x = x + inp

        return x[:, :, :H, :W]

    def check_image_size(self, x):
        _, _, h, w = x.size()
        mod_pad_h = (self.padder_size - h % self.padder_size) % self.padder_size
        mod_pad_w = (self.padder_size - w % self.padder_size) % self.padder_size
        x = F.pad(x, (0, mod_pad_w, 0, mod_pad_h))
        return x


def analyze_checkpoint(checkpoint_path: str) -> Dict[str, Any]:
    """
    Analyze a NAFNet checkpoint to determine the correct architecture.
    
    Args:
        checkpoint_path: Path to the checkpoint file
        
    Returns:
        Dictionary with architecture information
    """
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        # Handle different checkpoint formats
        if 'params' in checkpoint:
            state_dict = checkpoint['params']
        elif 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        elif 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        else:
            state_dict = checkpoint
        
        # Analyze encoder structure
        encoder_blocks = {}
        for key in state_dict.keys():
            if key.startswith('encoders.'):
                parts = key.split('.')
                if len(parts) >= 3:
                    encoder_idx = int(parts[1])
                    block_idx = int(parts[2])
                    if encoder_idx not in encoder_blocks:
                        encoder_blocks[encoder_idx] = set()
                    encoder_blocks[encoder_idx].add(block_idx)
        
        # Convert to list format
        enc_blk_nums = []
        for i in sorted(encoder_blocks.keys()):
            enc_blk_nums.append(max(encoder_blocks[i]) + 1)
        
        # Analyze middle blocks
        middle_blocks = set()
        for key in state_dict.keys():
            if key.startswith('middle_blks.'):
                parts = key.split('.')
                if len(parts) >= 2:
                    block_idx = int(parts[1])
                    middle_blocks.add(block_idx)
        
        middle_blk_num = max(middle_blocks) + 1 if middle_blocks else 12
        
        # Analyze decoder structure
        decoder_blocks = {}
        for key in state_dict.keys():
            if key.startswith('decoders.'):
                parts = key.split('.')
                if len(parts) >= 3:
                    decoder_idx = int(parts[1])
                    block_idx = int(parts[2])
                    if decoder_idx not in decoder_blocks:
                        decoder_blocks[decoder_idx] = set()
                    decoder_blocks[decoder_idx].add(block_idx)
        
        dec_blk_nums = []
        for i in sorted(decoder_blocks.keys()):
            dec_blk_nums.append(max(decoder_blocks[i]) + 1)
        
        return {
            'enc_blk_nums': enc_blk_nums,
            'dec_blk_nums': dec_blk_nums,
            'middle_blk_num': middle_blk_num,
            'width': 64  # Standard for width64 models
        }
        
    except Exception as e:
        logger.error(f"Error analyzing checkpoint: {e}")
        # Return default configuration
        return {
            'enc_blk_nums': [2, 2, 4, 28],
            'dec_blk_nums': [2, 2, 2, 2],
            'middle_blk_num': 12,
            'width': 64
        }


class FixedNAFNetLoader:
    """
    Fixed NAFNet model loader with proper GPU detection and error handling.
    """
    
    def __init__(self, model_path: str, device: Optional[str] = None):
        """
        Initialize the fixed NAFNet loader.
        
        Args:
            model_path: Path to the NAFNet checkpoint file
            device: Device to load the model on (auto-detected if None)
        """
        self.model_path = model_path
        self.device = device if device else detect_device()
        self.model: Optional[FixedNAFNet] = None
        self.is_loaded = False
        self.architecture_info = None
        
    def load_model(self) -> bool:
        """
        Load the NAFNet model from checkpoint with proper architecture detection.
        
        Returns:
            True if successful, False otherwise
        """
        try:
            logger.info(f"Loading fixed NAFNet from {self.model_path}")
            logger.info(f"Target device: {self.device}")
            
            if not os.path.exists(self.model_path):
                logger.error(f"Model file not found: {self.model_path}")
                return False
            
            # Analyze checkpoint to get correct architecture
            logger.info("Analyzing checkpoint architecture...")
            self.architecture_info = analyze_checkpoint(self.model_path)
            logger.info(f"Detected architecture: {self.architecture_info}")
            
            # Create model with detected configuration
            self.model = FixedNAFNet(
                img_channel=3,
                width=self.architecture_info['width'],
                middle_blk_num=self.architecture_info['middle_blk_num'],
                enc_blk_nums=self.architecture_info['enc_blk_nums'],
                dec_blk_nums=self.architecture_info['dec_blk_nums']
            )
            
            # Load checkpoint
            checkpoint = torch.load(self.model_path, map_location='cpu')
            
            # Handle different checkpoint formats
            if 'params' in checkpoint:
                state_dict = checkpoint['params']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            elif 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            else:
                state_dict = checkpoint
            
            # Remove 'module.' prefix if present (from DataParallel)
            new_state_dict = {}
            for k, v in state_dict.items():
                name = k.replace('module.', '') if k.startswith('module.') else k
                new_state_dict[name] = v
            
            # Load state dict with error handling
            try:
                self.model.load_state_dict(new_state_dict, strict=True)
                logger.info("Model loaded with strict=True")
            except RuntimeError as e:
                logger.warning(f"Strict loading failed: {e}")
                logger.info("Attempting to load with strict=False")
                self.model.load_state_dict(new_state_dict, strict=False)
            
            # Move to device and set eval mode
            # Handle CUDA availability gracefully
            try:
                if self.device == "cuda" and not torch.cuda.is_available():
                    logger.warning("CUDA requested but not available, falling back to CPU")
                    self.device = "cpu"
                
                self.model = self.model.to(self.device)
                self.model.eval()
            except Exception as e:
                logger.warning(f"Error moving model to {self.device}: {e}")
                logger.info("Falling back to CPU")
                self.device = "cpu"
                self.model = self.model.cpu()
                self.model.eval()
            
            # Test the model with a dummy input
            self._test_model()
            
            self.is_loaded = True
            logger.info(f"Fixed NAFNet loaded successfully on {self.device}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to load fixed NAFNet: {e}")
            self.is_loaded = False
            return False
    
    def _test_model(self):
        """Test the model with a dummy input to ensure it works."""
        try:
            dummy_input = torch.randn(1, 3, 64, 64)
            # Only move to device if it's not CUDA or if CUDA is actually available
            if self.device == "cpu" or torch.cuda.is_available():
                dummy_input = dummy_input.to(self.device)
            else:
                # Force CPU if CUDA is requested but not available
                self.device = "cpu"
                self.model = self.model.cpu()
                dummy_input = dummy_input.cpu()
                
            with torch.no_grad():
                output = self.model(dummy_input)
            logger.info(f"Model test successful: {dummy_input.shape} -> {output.shape}")
        except Exception as e:
            logger.warning(f"Model test failed: {e}")
            # Try CPU fallback
            if self.device != "cpu":
                logger.info("Attempting CPU fallback for model test")
                self.device = "cpu"
                self.model = self.model.cpu()
                dummy_input = torch.randn(1, 3, 64, 64).cpu()
                with torch.no_grad():
                    output = self.model(dummy_input)
                logger.info(f"CPU fallback test successful: {dummy_input.shape} -> {output.shape}")
            else:
                raise
    
    def process_image(self, image: np.ndarray) -> np.ndarray:
        """
        Process an image through the NAFNet model.
        
        Args:
            image: Input image as numpy array (H, W, 3) in BGR format
            
        Returns:
            Processed image as numpy array (H, W, 3) in BGR format
        """
        if not self.is_loaded or self.model is None:
            logger.warning("Model not loaded, returning original image")
            return image
        
        try:
            import cv2
            
            # Convert BGR to RGB
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # Normalize to [0, 1]
            image_normalized = image_rgb.astype(np.float32) / 255.0
            
            # Convert to tensor (C, H, W)
            image_tensor = torch.from_numpy(image_normalized).permute(2, 0, 1)
            image_tensor = image_tensor.unsqueeze(0)  # (1, C, H, W)
            
            # Move to device safely
            try:
                if self.device == "cuda" and torch.cuda.is_available():
                    image_tensor = image_tensor.to(self.device)
                elif self.device == "cuda":
                    logger.warning("CUDA not available, processing on CPU")
                    image_tensor = image_tensor.cpu()
                else:
                    image_tensor = image_tensor.to(self.device)
            except Exception as e:
                logger.warning(f"Error moving tensor to device: {e}, using CPU")
                image_tensor = image_tensor.cpu()
            
            # Process through model
            with torch.no_grad():
                output_tensor = self.model(image_tensor)
            
            # Convert back to numpy
            output_np = output_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()
            
            # Denormalize and convert to uint8
            output_np = np.clip(output_np * 255.0, 0, 255).astype(np.uint8)
            
            # Convert RGB back to BGR
            output_bgr = cv2.cvtColor(output_np, cv2.COLOR_RGB2BGR)
            
            return output_bgr
            
        except Exception as e:
            logger.error(f"Error processing image through fixed NAFNet: {e}")
            return image
    
    def get_info(self) -> Dict[str, Any]:
        """Get information about the loaded model."""
        return {
            'model_path': self.model_path,
            'device': self.device,
            'is_loaded': self.is_loaded,
            'architecture_info': self.architecture_info,
            'cuda_available': torch.cuda.is_available(),
            'device_count': torch.cuda.device_count() if torch.cuda.is_available() else 0
        }


def create_fixed_nafnet(model_path: str, device: Optional[str] = None) -> FixedNAFNetLoader:
    """
    Create and load a fixed NAFNet model.
    
    Args:
        model_path: Path to the NAFNet checkpoint
        device: Device to run on (auto-detected if None)
        
    Returns:
        Loaded FixedNAFNetLoader instance
    """
    loader = FixedNAFNetLoader(model_path, device)
    loader.load_model()
    return loader


if __name__ == "__main__":
    # Test the fixed implementation
    logging.basicConfig(level=logging.INFO)
    
    print("üîß Testing Fixed NAFNet Implementation")
    print("="*60)
    
    # Test device detection
    device = detect_device()
    print(f"Detected device: {device}")
    
    # Test model creation
    try:
        model = FixedNAFNet()
        print("‚úÖ Fixed NAFNet model created successfully")
        
        # Test forward pass with dummy data
        dummy_input = torch.randn(1, 3, 256, 256)
        with torch.no_grad():
            output = model(dummy_input)
        print(f"‚úÖ Forward pass successful: {dummy_input.shape} -> {output.shape}")
        
    except Exception as e:
        print(f"‚ùå Fixed NAFNet test failed: {e}")
    
    print("="*60)